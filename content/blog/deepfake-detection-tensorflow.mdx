---
title: "Detecting DeepFakes with TensorFlow: A Research Journey"
date: "2024-12-15"
excerpt: "How I achieved 88.37% accuracy in deepfake detection by benchmarking eight models across diverse GenAI image generation datasets."
tags: ["TensorFlow", "Deep Learning", "GenAI", "Computer Vision"]
---

# Detecting DeepFakes with TensorFlow: A Research Journey

During my research assistantship at the University of Michigan, I had the opportunity to work on one of the most pressing challenges in AI: detecting deepfake images. This post documents my approach and findings.

## The Problem

With the rapid advancement of generative AI, distinguishing between real and AI-generated images has become increasingly difficult. Our goal was to develop a robust detection system that could identify deepfakes across multiple generation models.

## Our Approach

### Model Benchmarking

We tested eight different deep learning architectures:

1. **Convolutional Neural Networks (CNNs)** - Baseline models
2. **Vision Transformers (ViTs)** - Attention-based approaches
3. **EfficientNet** - Optimized architectures
4. **ResNet variants** - Deep residual networks
5. **Custom ensembles** - Combining multiple models

### Dataset Diversity

Key to our success was using diverse training data:
- **Multiple GenAI models**: Stable Diffusion, DALL-E, Midjourney
- **Various image types**: Faces, landscapes, objects
- **Different quality levels**: From low-res to high-fidelity
- **Adversarial examples**: Images designed to fool detectors

## Technical Implementation

### Model Architecture

```python
# Simplified example of our detection pipeline
import tensorflow as tf

class DeepFakeDetector(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.backbone = tf.keras.applications.EfficientNetB4(
            weights='imagenet',
            include_top=False
        )
        self.classifier = tf.keras.Sequential([
            tf.keras.layers.GlobalAveragePooling2D(),
            tf.keras.layers.Dense(256, activation='relu'),
            tf.keras.layers.Dropout(0.5),
            tf.keras.layers.Dense(1, activation='sigmoid')
        ])
    
    def call(self, inputs):
        features = self.backbone(inputs)
        return self.classifier(features)
```

### Training Strategy

- **Transfer learning** from ImageNet
- **Data augmentation** to improve generalization
- **Class weighting** to handle imbalanced datasets
- **Cross-validation** across different model families

## Results

**88.37% accuracy** on our test set, with particularly strong performance on:
- Face manipulations (91.2%)
- Stable Diffusion outputs (89.5%)
- Mixed-model detection (86.8%)

## Building the Platform

I architected a full-stack Next.js platform for public testing:

- **Server-side API routes** for real-time inference
- **SQLite3 schema** for user feedback collection
- **Iterative retraining** pipeline based on user data

## Key Insights

1. **Ensemble methods outperform single models** - Combining multiple architectures improved accuracy by 5-7%
2. **Training data diversity is crucial** - Models trained on single GenAI sources failed on others
3. **Human-in-the-loop helps** - User feedback significantly improved model performance over time
4. **Edge cases matter** - Low-quality images and unusual compositions were common failure modes

## Future Directions

- Video deepfake detection
- Real-time processing optimization
- Adversarial robustness improvements
- Multi-modal detection (audio + video)

This research reinforced my belief in the importance of rigorous evaluation and diverse datasets when building AI systems.
